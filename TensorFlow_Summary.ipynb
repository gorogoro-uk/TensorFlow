{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow Summary.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqvFNqpq9l+64t220OrP7B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gorogoro-uk/TensorFlow/blob/master/TensorFlow_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA7cyM5aGPYf",
        "colab_type": "text"
      },
      "source": [
        "**TensorFlow Summary**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bORh2JamG7Dt",
        "colab_type": "text"
      },
      "source": [
        "**Data Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2d0FcBuGM_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. tensorflow dataset\n",
        "# eg MNIST\n",
        "# use datasets directly in model.fit()\n",
        "\n",
        "# 1.1 get data directly and use tf methods to split into test/train, data/label subsets\n",
        "import tensorflow as tf\n",
        "mnist_data = tf.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist_data.load_data()\n",
        "\n",
        "\n",
        "# 1.2 reshape train/test tensors\n",
        "# standarise pixel values to range 0-1\n",
        "import tensorflow as tf\n",
        "mnist_data = tf.keras.datasets.mnist\n",
        "(train_images, train_labels),(test_images, test_labels) = mnist_data.load_data()\n",
        "\n",
        "train_images = train_images.reshape(60000, 28, 28, 1)\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "train_images= train_images/255.0\n",
        "test_images = test_images/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe45MI8vKkTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. image zip file sourced from internet with Image Data Generator\n",
        "# eg happy/sad images\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# prepare directories\n",
        "BASE = Path(os.getcwd()) / 'happysad'\n",
        "HS_DATA = BASE / 'hs_data'\n",
        "ZIP_DEST = BASE / 'happy-or-sad.zip'\n",
        "ZIP_URL = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\"\n",
        "\n",
        "if not os.path.exists(BASE):\n",
        "    os.mkdir(BASE)\n",
        "if not os.path.exists(HS_DATA):\n",
        "    os.mkdir(HS_DATA)\n",
        "\n",
        "# download data file & unzip\n",
        "urllib.request.urlretrieve(ZIP_URL, ZIP_DEST)\n",
        "zip_ref = zipfile.ZipFile(ZIP_DEST, 'r')\n",
        "zip_ref.extractall(HS_DATA)\n",
        "zip_ref.close()\n",
        "\n",
        "# image data generator, flow from directory\n",
        "# creates batches of images to feed to model\n",
        "# label data is created automatically based on directory structure\n",
        "# image data generator is passed to model.fit()\n",
        "image_data_gen = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "train_data_gen = image_data_gen.flow_from_directory(\n",
        "    HS_DATA,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=10,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i21BBrNJMA_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3. image data zip file\n",
        "# manually create train/test split and move to directory\n",
        "# image \n",
        "# eg cats/dogs\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import random\n",
        "from shutil import copyfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# prepare data directories\n",
        "BASE = Path(os.getcwd()) / 'catdog'   # base directory\n",
        "ZIP_DEST = BASE / 'cats_dogs.zip'     # zip file destination\n",
        "CAT_SOURCE = BASE / 'PetImages/Cat'\n",
        "DOG_SOURCE = BASE / 'PetImages/Dog'\n",
        "TRAIN_DEST = BASE / 'train'           # training images\n",
        "TEST_DEST = BASE / 'test'             # testing images\n",
        "TRAIN_CAT = BASE / 'train/cat'        # cat training images\n",
        "TEST_CAT = BASE / 'test/cat'          # cat testing images\n",
        "TRAIN_DOG = BASE / 'train/dog'        # dog training images\n",
        "TEST_DOG = BASE / 'test/dog'          # dog testing images\n",
        "\n",
        "# create directories\n",
        "if not os.path.exists(BASE):\n",
        "    os.mkdir(BASE)\n",
        "if not os.path.exists(TRAIN_DEST):\n",
        "    os.mkdir(TRAIN_DEST)\n",
        "if not os.path.exists(TEST_DEST):\n",
        "    os.mkdir(TEST_DEST)\n",
        "if not os.path.exists(TRAIN_CAT):\n",
        "    os.mkdir(TRAIN_CAT)\n",
        "if not os.path.exists(TRAIN_DOG):\n",
        "    os.mkdir(TRAIN_DOG)\n",
        "if not os.path.exists(TEST_CAT):\n",
        "    os.mkdir(TEST_CAT)\n",
        "if not os.path.exists(TEST_DOG):\n",
        "    os.mkdir(TEST_DOG)\n",
        "\n",
        "# download & unzip data\n",
        "URL = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
        "urllib.request.urlretrieve(URL, ZIP_DEST)\n",
        "zip_ref = zipfile.ZipFile(ZIP_DEST, 'r')\n",
        "zip_ref.extractall(BASE)\n",
        "zip_ref.close()\n",
        "\n",
        "# split data into train & test\n",
        "TRAIN_SIZE = 0.90\n",
        "\n",
        "def split_data(source, train, test, split):\n",
        "    \"\"\" shuffle images, copy to directory, split into train/test \"\"\"\n",
        "\n",
        "    # list of image file names\n",
        "    files = []\n",
        "    for filename in os.listdir(source):\n",
        "        file = source / filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    train_length = int(len(files) * split)\n",
        "    test_length = int(len(files) - train_length)\n",
        "\n",
        "    # shuffle dataset images\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "\n",
        "    # define train, test split\n",
        "    train_set = shuffled_set[0:train_length]\n",
        "    test_set = shuffled_set[-test_length:]\n",
        "\n",
        "    # move files to train or test directory\n",
        "    for filename in train_set:\n",
        "        this_file = source / filename\n",
        "        destination = train / filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in test_set:\n",
        "        this_file = source / filename\n",
        "        destination = test / filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "split_data(CAT_SOURCE, TRAIN_CAT, TEST_CAT, TRAIN_SIZE)\n",
        "split_data(DOG_SOURCE, TRAIN_DOG, TEST_DOG, TRAIN_SIZE)\n",
        "\n",
        "# image data generator, flow from directory\n",
        "# data augmentation: rescale, rotate, shift, shear, zoom, flip\n",
        "# define batch, image size, create binary labels based on directory\n",
        "# image data generator is passed to model.fit()\n",
        "train_image_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          rotation_range=40,\n",
        "                                          width_shift_range=0.2,\n",
        "                                          height_shift_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          zoom_range=0.2,\n",
        "                                          horizontal_flip=True,\n",
        "                                          fill_mode='nearest')\n",
        "train_datagen = train_image_datagen.flow_from_directory(TRAIN_DEST,\n",
        "                                                    batch_size=100,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "test_image_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          rotation_range=40,\n",
        "                                          width_shift_range=0.2,\n",
        "                                          height_shift_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          zoom_range=0.2,\n",
        "                                          horizontal_flip=True,\n",
        "                                          fill_mode='nearest')\n",
        "test_datagen = test_image_datagen.flow_from_directory(TEST_DEST,\n",
        "                                                    batch_size=100,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}