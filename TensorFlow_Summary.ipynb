{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow Summary.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+EygE9gMPWOCvWEi8GPYJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gorogoro-uk/TensorFlow/blob/master/TensorFlow_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA7cyM5aGPYf",
        "colab_type": "text"
      },
      "source": [
        "**TensorFlow Summary**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bORh2JamG7Dt",
        "colab_type": "text"
      },
      "source": [
        "**Data Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2d0FcBuGM_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. tensorflow dataset\n",
        "# eg MNIST\n",
        "# use datasets directly in model.fit()\n",
        "\n",
        "# 1.1 get data directly and use tf methods to split into test/train, data/label subsets\n",
        "import tensorflow as tf\n",
        "mnist_data = tf.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist_data.load_data()\n",
        "\n",
        "\n",
        "# 1.2 reshape train/test tensors\n",
        "# standarise pixel values to range 0-1\n",
        "import tensorflow as tf\n",
        "mnist_data = tf.keras.datasets.mnist\n",
        "(train_images, train_labels),(test_images, test_labels) = mnist_data.load_data()\n",
        "\n",
        "train_images = train_images.reshape(60000, 28, 28, 1)\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "train_images= train_images/255.0\n",
        "test_images = test_images/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe45MI8vKkTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. image zip file sourced from internet with Image Data Generator\n",
        "# eg happy/sad images\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# prepare directories\n",
        "BASE = Path(os.getcwd()) / 'happysad'\n",
        "HS_DATA = BASE / 'hs_data'\n",
        "ZIP_DEST = BASE / 'happy-or-sad.zip'\n",
        "ZIP_URL = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\"\n",
        "\n",
        "if not os.path.exists(BASE):\n",
        "    os.mkdir(BASE)\n",
        "if not os.path.exists(HS_DATA):\n",
        "    os.mkdir(HS_DATA)\n",
        "\n",
        "# download data file & unzip\n",
        "urllib.request.urlretrieve(ZIP_URL, ZIP_DEST)\n",
        "zip_ref = zipfile.ZipFile(ZIP_DEST, 'r')\n",
        "zip_ref.extractall(HS_DATA)\n",
        "zip_ref.close()\n",
        "\n",
        "# image data generator, flow from directory\n",
        "# creates batches of images to feed to model\n",
        "# label data is created automatically based on directory structure\n",
        "# image data generator is passed to model.fit()\n",
        "image_data_gen = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "train_data_gen = image_data_gen.flow_from_directory(\n",
        "    HS_DATA,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=10,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i21BBrNJMA_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3. image zip file sourced from internet with Image Data Generator\n",
        "# manually create train/test split and move to directory\n",
        "# image \n",
        "# eg cats/dogs\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import random\n",
        "from shutil import copyfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# prepare data directories\n",
        "BASE = Path(os.getcwd()) / 'catdog'   # base directory\n",
        "ZIP_DEST = BASE / 'cats_dogs.zip'     # zip file destination\n",
        "CAT_SOURCE = BASE / 'PetImages/Cat'\n",
        "DOG_SOURCE = BASE / 'PetImages/Dog'\n",
        "TRAIN_DEST = BASE / 'train'           # training images\n",
        "TEST_DEST = BASE / 'test'             # testing images\n",
        "TRAIN_CAT = BASE / 'train/cat'        # cat training images\n",
        "TEST_CAT = BASE / 'test/cat'          # cat testing images\n",
        "TRAIN_DOG = BASE / 'train/dog'        # dog training images\n",
        "TEST_DOG = BASE / 'test/dog'          # dog testing images\n",
        "\n",
        "# create directories\n",
        "if not os.path.exists(BASE):\n",
        "    os.mkdir(BASE)\n",
        "if not os.path.exists(TRAIN_DEST):\n",
        "    os.mkdir(TRAIN_DEST)\n",
        "if not os.path.exists(TEST_DEST):\n",
        "    os.mkdir(TEST_DEST)\n",
        "if not os.path.exists(TRAIN_CAT):\n",
        "    os.mkdir(TRAIN_CAT)\n",
        "if not os.path.exists(TRAIN_DOG):\n",
        "    os.mkdir(TRAIN_DOG)\n",
        "if not os.path.exists(TEST_CAT):\n",
        "    os.mkdir(TEST_CAT)\n",
        "if not os.path.exists(TEST_DOG):\n",
        "    os.mkdir(TEST_DOG)\n",
        "\n",
        "# download & unzip data\n",
        "URL = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
        "urllib.request.urlretrieve(URL, ZIP_DEST)\n",
        "zip_ref = zipfile.ZipFile(ZIP_DEST, 'r')\n",
        "zip_ref.extractall(BASE)\n",
        "zip_ref.close()\n",
        "\n",
        "# split data into train & test\n",
        "TRAIN_SIZE = 0.90\n",
        "\n",
        "def split_data(source, train, test, split):\n",
        "    \"\"\" shuffle images, copy to directory, split into train/test \"\"\"\n",
        "\n",
        "    # list of image file names\n",
        "    files = []\n",
        "    for filename in os.listdir(source):\n",
        "        file = source / filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    train_length = int(len(files) * split)\n",
        "    test_length = int(len(files) - train_length)\n",
        "\n",
        "    # shuffle dataset images\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "\n",
        "    # define train, test split\n",
        "    train_set = shuffled_set[0:train_length]\n",
        "    test_set = shuffled_set[-test_length:]\n",
        "\n",
        "    # move files to train or test directory\n",
        "    for filename in train_set:\n",
        "        this_file = source / filename\n",
        "        destination = train / filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in test_set:\n",
        "        this_file = source / filename\n",
        "        destination = test / filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "split_data(CAT_SOURCE, TRAIN_CAT, TEST_CAT, TRAIN_SIZE)\n",
        "split_data(DOG_SOURCE, TRAIN_DOG, TEST_DOG, TRAIN_SIZE)\n",
        "\n",
        "# image data generator, flow from directory\n",
        "# data augmentation: rescale, rotate, shift, shear, zoom, flip\n",
        "# define batch, image size, create binary labels based on directory\n",
        "# image data generator is passed to model.fit()\n",
        "train_image_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          rotation_range=40,\n",
        "                                          width_shift_range=0.2,\n",
        "                                          height_shift_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          zoom_range=0.2,\n",
        "                                          horizontal_flip=True,\n",
        "                                          fill_mode='nearest')\n",
        "train_datagen = train_image_datagen.flow_from_directory(TRAIN_DEST,\n",
        "                                                    batch_size=100,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "test_image_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          rotation_range=40,\n",
        "                                          width_shift_range=0.2,\n",
        "                                          height_shift_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          zoom_range=0.2,\n",
        "                                          horizontal_flip=True,\n",
        "                                          fill_mode='nearest')\n",
        "test_datagen = test_image_datagen.flow_from_directory(TEST_DEST,\n",
        "                                                    batch_size=100,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQG5AuzlONMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. image zip file sourced from internet with Image Data Generator\n",
        "# separate train & test datasets\n",
        "# eg. horse/human images\n",
        "\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#  prepare data directories\n",
        "CWD = Path(os.getcwd())\n",
        "BASE = CWD / 'horsehuman'\n",
        "TRAIN = BASE / 'train'\n",
        "TEST = BASE / 'test'\n",
        "TRAIN_HORSE = TRAIN / 'horses'\n",
        "TRAIN_HUMAN = TRAIN / 'humans'\n",
        "TEST_HORSE = TEST / 'horses'\n",
        "TEST_HUMAN = TEST / 'humans'\n",
        "\n",
        "if not os.path.exists(BASE):\n",
        "    os.mkdir(BASE)\n",
        "if not os.path.exists(TRAIN):\n",
        "    os.mkdir(TRAIN)\n",
        "if not os.path.exists(TEST):\n",
        "    os.mkdir(TEST)\n",
        "\n",
        "# get train & test datasets\n",
        "TRAIN_URL = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\"\n",
        "TEST_URL = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\"\n",
        "ZIP_TRAIN = TRAIN / 'horse-or-human.zip'\n",
        "ZIP_TEST = TEST / 'validation-horse-or-human.zip'\n",
        "\n",
        "urllib.request.urlretrieve(TRAIN_URL,TRAIN / ZIP_TRAIN)\n",
        "urllib.request.urlretrieve(TEST_URL,TEST / ZIP_TEST)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(ZIP_TRAIN, 'r')\n",
        "zip_ref.extractall(TRAIN)\n",
        "zip_ref.close()\n",
        "zip_ref = zipfile.ZipFile(ZIP_TEST, 'r')\n",
        "zip_ref.extractall(TEST)\n",
        "zip_ref.close()\n",
        "\n",
        "# image data generator, flow from directory\n",
        "# data augmentation: rescale, rotate, shift, shear, zoom, flip\n",
        "# define batch, image size, create binary labels based on directory\n",
        "# image data generator is passed to model.fit()\n",
        "# augmentation not required on test images\n",
        "train_image_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          rotation_range=40,\n",
        "                                          width_shift_range=0.2,\n",
        "                                          height_shift_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          zoom_range=0.2,\n",
        "                                          horizontal_flip=True)\n",
        "\n",
        "train_datagen = train_image_datagen.flow_from_directory(TRAIN,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "test_image_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_datagen = test_image_datagen.flow_from_directory(TEST,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRmxIUkjPSp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5. csv file sourced from internet with Image Data Generator\n",
        "# extract data & label from csv file\n",
        "# separate train & test files\n",
        "# eg. sign MNIST images\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# prepare directories\n",
        "CWD = Path(os.getcwd())\n",
        "TRAIN_FILE = CWD / 'signlanguage/sign_mnist_train.csv'\n",
        "TEST_FILE = CWD / 'signlanguage/sign_mnist_test.csv'\n",
        "\n",
        "# read data from csv file, line by line\n",
        "# image pixel values flattened in one row, reshape for use\n",
        "def prepare_data(file_name):\n",
        "    with open(file_name) as data_file:\n",
        "        csv_reader = csv.reader(data_file, delimiter=',')\n",
        "        first_line = True\n",
        "        label_temp = []\n",
        "        image_temp = []\n",
        "        for row in csv_reader:\n",
        "            if first_line:\n",
        "                first_line = False\n",
        "            else:\n",
        "                label_temp.append(row[0])\n",
        "                image_row = row[1:785]\n",
        "                image_array = np.reshape(image_row, (28,28))\n",
        "                image_temp.append(image_array)\n",
        "    labels = np.array(label_temp).astype('float')\n",
        "    images = np.array(image_temp).astype('float')\n",
        "    return images, labels\n",
        "\n",
        "x_train, y_train = prepare_data(TRAIN_FILE)\n",
        "x_test, y_test = prepare_data(TEST_FILE)\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=3)\n",
        "x_test = np.expand_dims(x_test, axis=3)\n",
        "\n",
        "# image data generator, flow\n",
        "# data augmentation: rescale, rotate, shift, shear, zoom, flip\n",
        "# define batch & data/label datsets\n",
        "# image data generator is passed to model.fit()\n",
        "# augmentation not required on test images\n",
        "train_image_datagen = ImageDataGenerator(rescale=1/255.,\n",
        "                                    rotation_range=40,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode='nearest')\n",
        "train_datagen = train_image_datagen.flow(x_train, y_train, batch_size=32)\n",
        "\n",
        "test_image_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = test_image_datagen.flow(x_test, y_test, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}